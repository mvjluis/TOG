\chapter{Estado del arte}
\textit{\textbf{Resumen:} La clasificación y detección de objetos es un importante campo dentro de la visión computacional, en los últimos años las redes neuronales convolucionales se han ganado el lugar en este campo al tener un buen desempeño en competencias y en las aplicaciones que necesitan aprendizaje que sería muy complicado si se deseara crear un algoritmo con reglas manuales, se presenta una breve recopilación de trabajos de interés dentro de las redes neuronales convolucionales}

\section{Clasificación}
Dentro de los algoritmos de clasificación de imágenes de redes neuronales se encuentran varios trabajos que han llevado al estado del arte hoy en día, a continuación se presentan algunos de relevancia debido a los conceptos y novedades que ha agregado al campo de la clasificación y locaclización usando redes neuronales.

\subsection{Aprendizaje basado en gradiente descendiente aplicado al reconocimiento de documentos - LeCun}
En éste artículo se nos muestra que dada una apropiada arquitectura de red neuronal, los algortimos de aprendizaje basados en el gradiente descendiente pueden ser usados para sintetizar un clasificador, tal como se muestra en su artículo, la red presentada apoya para la clasificación de caráteres escritos.
La red utilizada, es una red neuronal convolucional las cuales tienen un gran desempeño en clasificación de imágenes. La arquitectura de la red neuronal convolucional presentada se le llama LeNet-5 que consta de 3 capas convolucionales, 2 capas de muestreo y 2 capas completamente conectadas. El método usado para la actualización de los parámetros es el método de gradiente descendiente estocástico.
Durante el desarrollo del proyecto se utilizara el tipo de arquitectura de red convolucional para la clasificación de los objetos de interés, así como se aplicarán ciertas modificaciones de artículos más recientes.

\subsection{Clasificación ImageNet con redes neuronales convolucionales profundas - Krizhevsky}
En este artículo Krizhevsky presenta con una red nueronal convolucional tal y como lo hace LeCun, la aportación de este trabajo es la introducción de un método de regularización para prevenir el sobre ajuste de la red, este método de regularización es llamado "dropout". Este método consiste en forzar el valor a 0 a las neuronas en capas ocultas con una probabilidad de 0.5. De ese modo dichas neuronas no contribuyen a la clasificación haciendo que el entrenamiento no dependa de las mismas neuronas para realizar la clasificación y por lo tanto obliga a la red a aprender caractisticas de manera más robusta. De esta manera se evita el sobre ajuste pero el costo es que se requiere mayor cantidad de entrenamiento para que la red neuronal converja.
Durante el trabajo utilizaremos técnicas de normalización como el presentado por Krizhevsky, para evitar el sobre ajuste.

\subsection{Red en Red - Lin}
En el atículo presentado por Lin et al, se introduce una modificación a la red neuronal convolucional. En la capa de convolución normalmente se utilizan kernel locales para obtener los mapas de carecterísticas, en su lugar en éste trabajo se propone reemplazarlo por una red neuronal basados en el perceptrón, para ser el responsable de obtener los mapas de caracteríscas. Además agrega un método de regularización llamado "Global average pooling" o muestreo promedio global el cual toma el promedio de cada mapa de características el cuál se pasa a una capa "softmax", con cual los autores describen que refuerza las correspondencias entre los mapas de características y categorías, y es más robusto en translaciones espaciales del objeto de interés.

\subsection{Redes convolucionales muy profundas para reconocimiento de imágenes a grande escala - Simonyan}
Hasta ahora en los trabajos se han introducido cambios en las capas de convolución, pero qué tal aumentar o disminuir la profundidade de la red. En cuanto al manejo de la profundidad de la red neuronal, Simonyan y Andrew presentaron en su artículo el efecto de hacer redes más profundas y su precisión al modificarlas, con profundidad de hasta 19 capas, en su investigación arrojaron que se puede aumentar la precisión haciendo más profunda la red logrando tener buenos resultados y disminuyendo la dimensión de filtros convolucionales o kernels locales, en este caso de dimensión 3x3.

\subsection{Aprendizeje residual profundo para reconocimiento de imágenes - He}
Siguiendo con los trabajos que experimentan con redes neuronales más profundas, He et al, que expone que diseñar redes neuronales muy profundas lleva a una degradación durante el entrenamiento donde la precisión se satura y comienza un degradamiento. Como parte de enfrentar este comportamiento, He et al, introducen un nuevo tipo de bloque a las redes neuronales llamado aprendizaje residual, el cual se tienen dos capas, la primera capa procesa normalmente la información de entrada, pero la segunda capa, toma como entrada, los datos de salida de la primera capa más los datos de entrada de la primera capa. Con esto se muestra que pueden diseñar redes con mayor porfundidad y manejando el degradamiento que habían observado con las redes neuronals habituales. Con este tipo de bloque en la red neuronal, experimentaron con profundidades de hasta 152 capas a diferencia de las 19 capas usadas por Simonyan, este tipo de red se llamó ResNet.

\subsection{Iendo profundo con convoluciones - Szegedy}
En este trabajo Szegedy et al, introducen un nueva arquitectura llamada "Inception", esta arquitectura se basa en un modulo de "inception", en este modulo todos los kernels son aprendidos y que es un conjunto de filtros de diferentes dimensiones que procesan la entrada y al final se combinan como preparación para el siguiente módulo de "inception".

\section{Localización y clasificación}
Como parte de los problemas relacionados en la visión computacional, el problema que se aborda en este proyecto no solo es la clasificación sino también la localización del objetos dentro de la imagen. Existen varias implementaciones para abordar estas tareas en conjunto.

\subsection{Solo observas una vez: Unificado, detección de objetos en tiempo real - Redmon}
Parte del manejo de imágenes no solamente es la clasificación sino también la localización en un imagen de varios elementos de interes. En este trabajo Redmon et al, presenta una arquitectura que diferente a lo que se había hecho en trabajos previos donde la detección de objetos se han dividido en dos etapas, la localización y la clasificación. Redmon et al, propone una sola etapa en su arquitectura YOLO. Arquitecturas previas parten la imagen en varias regiones, donde genera cuadros delimitadores potenciales para ejecutar la clasificación sobre estas cajas protenciales. Al final un post procesamiento es realizado para refinar los cuadros delimitadores, eliminar duplicados de imagen y generar las clasificaciones finales.
YOLO predice simultaneamente multiples cajas delimitadoras y clases de probabilidad de cada una. Esta arquitectura es entrenada para en imagenes completas para la optimización. Por lo que aprende del objeto de interés y su contexto, lo que lo lleva a generar menos falsos en imagenes que no son de interés. En contra tiene que al generar menos cajas delimitadoras y tiene un límite de predicciónes por cada una, va por detrás de otros modelos en la detección de objetos pequeños.